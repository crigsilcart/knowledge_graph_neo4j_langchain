{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristhiansilvac./Documents/code/KnowledgeGraph/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cristhiansilvac./nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.openai_functions import PydanticOutputFunctionsParser\n",
    "from langchain_community.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "import nltk\n",
    "_ = nltk.download('punkt')\n",
    "\n",
    "_ = load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document loader and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NLTKTextSplitter(chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 586, which is longer than the specified 500\n",
      "Created a chunk of size 625, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 511, which is longer than the specified 500\n",
      "Created a chunk of size 817, which is longer than the specified 500\n",
      "Created a chunk of size 581, which is longer than the specified 500\n",
      "Created a chunk of size 599, which is longer than the specified 500\n",
      "Created a chunk of size 668, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 892, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 546, which is longer than the specified 500\n",
      "Created a chunk of size 504, which is longer than the specified 500\n",
      "Created a chunk of size 514, which is longer than the specified 500\n",
      "Created a chunk of size 541, which is longer than the specified 500\n",
      "Created a chunk of size 538, which is longer than the specified 500\n",
      "Created a chunk of size 542, which is longer than the specified 500\n",
      "Created a chunk of size 510, which is longer than the specified 500\n",
      "Created a chunk of size 632, which is longer than the specified 500\n",
      "Created a chunk of size 505, which is longer than the specified 500\n",
      "Created a chunk of size 572, which is longer than the specified 500\n",
      "Created a chunk of size 604, which is longer than the specified 500\n",
      "Created a chunk of size 761, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"../A Brief History of Time: From the Big Bang to Black Holes.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "chunks = splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text:str):\n",
    "    final_text = text\n",
    "    final_text = final_text.lower()\n",
    "    final_text = re.sub(\"[áä]\",\"a\", final_text)\n",
    "    final_text = re.sub(\"[éë]\",\"e\", final_text)\n",
    "    final_text = re.sub(\"[íï]\",\"i\", final_text)\n",
    "    final_text = re.sub(\"[óö]\",\"o\", final_text)\n",
    "    final_text = re.sub(\"[úü]\",\"u\", final_text)\n",
    "    final_text = re.sub(\"\\\"\",\"\\'\", final_text)\n",
    "    final_text = re.sub(\"[^A-Za-z0-9\\s\\-\\.\\,\\;\\:]+\",\"\", final_text)\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    chunk.page_content = clean_text(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = open(\"../system_instructions.txt\",\"r\").read()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_instructions),\n",
    "    (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
    "    (\"human\", \"Tip: Make sure to answer in the correct format\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KnowledgeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain_community.graphs.graph_document import Node as BaseNode\n",
    "from langchain_community.graphs.graph_document import Relationship as BaseRelationship\n",
    "from langchain_community.graphs.graph_document import GraphDocument\n",
    "\n",
    "class Property(BaseModel):\n",
    "  \"\"\"A single property consisting of key and value\"\"\"\n",
    "  key: str = Field(..., description=\"key\")\n",
    "  value: str = Field(..., description=\"value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(None, description=\"List of relationship properties\")\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(..., description=\"List of relationships in the knowledge graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputFunctionsParser(pydantic_schema=KnowledgeGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_functions = [convert_pydantic_to_openai_function(KnowledgeGraph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm.bind(functions=openai_functions),\n",
    "    prompt=prompt,\n",
    "    output_parser=parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Op1) Processing Docs Splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i,docs in enumerate(data):\n",
    "    print(\"doc\",i)\n",
    "    try:\n",
    "        results.append(chain.invoke(docs))\n",
    "    except Exception as e:\n",
    "        print(\"ERROR\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
    "    if node.properties:\n",
    "        properties = {prop.key: prop.value for prop in node.properties}\n",
    "    else:\n",
    "        properties = {\n",
    "            \"name\": node.id.title()\n",
    "        }\n",
    "\n",
    "    return BaseNode(\n",
    "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
    "    )\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = {prop.key: prop.value for prop in rel.properties} if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_doc(res):\n",
    "    graph_document = GraphDocument(\n",
    "        nodes = [map_to_base_node(node) for node in res[\"text\"].nodes],\n",
    "        relationships = [map_to_base_relationship(rel) for rel in res[\"text\"].rels],\n",
    "        source = res[\"input\"]\n",
    "    )\n",
    "    \n",
    "    return graph_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = []\n",
    "for res in results:\n",
    "    graph_documents.append(create_graph_doc(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def save_data(data, file):\n",
    "        objs = []\n",
    "        for d in data:\n",
    "            obj_str = d.json()\n",
    "            obj = json.loads(obj_str)\n",
    "            objs.append(obj)\n",
    "        with open(file, \"w\") as f:\n",
    "            json.dump(objs, f)\n",
    "    save_data(graph_documents, \"../data/history_of_time_graph_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Op2) Use Data backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data_res = []\n",
    "        for d in data:\n",
    "            data_res.append(GraphDocument.parse_obj(d))\n",
    "            \n",
    "        return data_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = load_data(\"../data/history_of_time_graph_3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4J Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "graph = Neo4jGraph(url=url,\n",
    "    username=username,\n",
    "    password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the current graph\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Docs to Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "error_indexes = [4]\n",
    "arr = [x for x in range(len(graph_documents)) if x not in error_indexes]\n",
    "\n",
    "for x in arr:\n",
    "    try:\n",
    "        print(x)\n",
    "        graph.add_graph_documents([graph_documents[x]], include_source=True)\n",
    "        graph.refresh_schema()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_props': {'Document': [{'property': 'text', 'type': 'STRING'}, {'property': 'source', 'type': 'STRING'}, {'property': 'page', 'type': 'INTEGER'}], 'Chapter': [{'property': 'title', 'type': 'STRING'}, {'property': 'id', 'type': 'STRING'}], 'Section': [{'property': 'id', 'type': 'STRING'}, {'property': 'title', 'type': 'STRING'}], 'Person': [{'property': 'name', 'type': 'STRING'}, {'property': 'id', 'type': 'STRING'}, {'property': 'description', 'type': 'STRING'}, {'property': 'deathDate', 'type': 'STRING'}, {'property': 'birthDate', 'type': 'STRING'}], 'Book': [{'property': 'title', 'type': 'STRING'}, {'property': 'id', 'type': 'STRING'}, {'property': 'author', 'type': 'STRING'}, {'property': 'publicationYear', 'type': 'STRING'}], 'Satellite': [{'property': 'id', 'type': 'STRING'}, {'property': 'name', 'type': 'STRING'}, {'property': 'fullForm', 'type': 'STRING'}], 'Celestial body': [{'property': 'id', 'type': 'STRING'}, {'property': 'name', 'type': 'STRING'}], 'Concept': [{'property': 'description', 'type': 'STRING'}, {'property': 'id', 'type': 'STRING'}, {'property': 'name', 'type': 'STRING'}]}, 'rel_props': {}, 'relationships': [{'start': 'Document', 'type': 'MENTIONS', 'end': 'Section'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Chapter'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Satellite'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Book'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Person'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Celestial body'}, {'start': 'Document', 'type': 'MENTIONS', 'end': 'Concept'}, {'start': 'Chapter', 'type': 'FOLLOWED_BY', 'end': 'Chapter'}, {'start': 'Chapter', 'type': 'FOLLOWED_BY', 'end': 'Section'}, {'start': 'Section', 'type': 'FOLLOWED_BY', 'end': 'Chapter'}, {'start': 'Section', 'type': 'FOLLOWED_BY', 'end': 'Section'}, {'start': 'Person', 'type': 'AUTHORED', 'end': 'Book'}, {'start': 'Person', 'type': 'PROPOSED_MODEL', 'end': 'Celestial body'}, {'start': 'Person', 'type': 'OBJECTION', 'end': 'Concept'}, {'start': 'Person', 'type': 'ARGUED_FOR', 'end': 'Concept'}, {'start': 'Person', 'type': 'INFLUENCEDBY', 'end': 'Person'}, {'start': 'Person', 'type': 'OPPOSED_TO', 'end': 'Concept'}, {'start': 'Person', 'type': 'EXAMINED', 'end': 'Concept'}, {'start': 'Person', 'type': 'LAWSOFMOTION', 'end': 'Person'}, {'start': 'Person', 'type': 'BASISOF', 'end': 'Person'}, {'start': 'Person', 'type': 'LAWSOFGRAVITY', 'end': 'Person'}, {'start': 'Person', 'type': 'AUTHOROF', 'end': 'Book'}, {'start': 'Satellite', 'type': 'MENTIONED', 'end': 'Book'}, {'start': 'Concept', 'type': 'OPPOSITE', 'end': 'Concept'}, {'start': 'Concept', 'type': 'BALANCE', 'end': 'Concept'}, {'start': 'Concept', 'type': 'DISCUSSED_IN', 'end': 'Concept'}, {'start': 'Concept', 'type': 'ASSOCIATED_WITH', 'end': 'Concept'}, {'start': 'Concept', 'type': 'EXPLAINED_BY', 'end': 'Concept'}, {'start': 'Concept', 'type': 'SUFFICIENT_FOR', 'end': 'Concept'}, {'start': 'Concept', 'type': 'DIFFICULT_TO_JUSTIFY_ON', 'end': 'Concept'}, {'start': 'Concept', 'type': 'HAS_GIVEN', 'end': 'Concept'}, {'start': 'Concept', 'type': 'MAY_NOT_AID', 'end': 'Concept'}, {'start': 'Concept', 'type': 'MAY_NOT_EVEN', 'end': 'Concept'}, {'start': 'Concept', 'type': 'CRAVED_BY', 'end': 'Concept'}, {'start': 'Concept', 'type': 'GOAL_IS', 'end': 'Concept'}, {'start': 'Concept', 'type': 'DATEBACKTO', 'end': 'Person'}, {'start': 'Concept', 'type': 'BELIEF', 'end': 'Person'}, {'start': 'Concept', 'type': 'EXPERIMENT', 'end': 'Person'}]}\n"
     ]
    }
   ],
   "source": [
    "print(graph.structured_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt4 = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    cypher_llm=llm,#llm_gpt4,\n",
    "    qa_llm=llm,\n",
    "    validate_cypher=True,\n",
    "    verbose=True,\n",
    "    top_k=1,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Person {name: \"Immanuel Kant\"})-[:AUTHORED|PROPOSED_MODEL|OBJECTION|ARGUED_FOR|INFLUENCEDBY|OPPOSED_TO|EXAMINED|LAWSOFMOTION|BASISOF|LAWSOFGRAVITY|AUTHOROF]->(related)\n",
      "RETURN p, related\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'tell me everything Immanuel Kant did?',\n",
       " 'result': \"I'm sorry, but I don't have any information on what Immanuel Kant did.\",\n",
       " 'intermediate_steps': [{'query': 'cypher\\nMATCH (p:Person {name: \"Immanuel Kant\"})-[:AUTHORED|PROPOSED_MODEL|OBJECTION|ARGUED_FOR|INFLUENCEDBY|OPPOSED_TO|EXAMINED|LAWSOFMOTION|BASISOF|LAWSOFGRAVITY|AUTHOROF]->(related)\\nRETURN p, related\\n'},\n",
       "  {'context': []}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher_chain.invoke({\"query\": \"tell me everything Immanuel Kant did?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Person)-[r]-(x) WHERE p.id = 'Aristotle' RETURN p, type(r), x\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p': {'description': 'Greek philosopher who believed in an eternal universe', 'id': 'Aristotle'}, 'type(r)': 'INFLUENCEDBY', 'x': {'deathDate': '1642', 'id': 'Galileo', 'birthDate': '1564'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'who has connections with Aritotle? (Aristotle is an id)',\n",
       " 'result': 'Aristotle was influenced by a Greek philosopher who believed in an eternal universe.',\n",
       " 'intermediate_steps': [{'query': \"cypher\\nMATCH (p:Person)-[r]-(x) WHERE p.id = 'Aristotle' RETURN p, type(r), x\\n\"},\n",
       "  {'context': [{'p': {'description': 'Greek philosopher who believed in an eternal universe',\n",
       "      'id': 'Aristotle'},\n",
       "     'type(r)': 'INFLUENCEDBY',\n",
       "     'x': {'deathDate': '1642', 'id': 'Galileo', 'birthDate': '1564'}}]}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher_chain.invoke({\"query\": \"who has connections with Aritotle? (Aristotle is an id)\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
